{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d596c5a3-bdb1-49cf-8781-d3f088d267f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l'segmentation-models-pytorch' already seems to be installed. Not modifying\n",
      "existing installation in\n",
      "'/home/hardik/.local/share/pipx/venvs/segmentation-models-pytorch'. Pass\n",
      "'--force' to force installation.\n",
      "\u001b[?25h\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipx install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b57b02a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msegmentation_models_pytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01malbumentations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mA\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib as jlb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==================== Configuration ====================\n",
    "CONFIG = {\n",
    "    'ims_path': r'/home/hardik/Desktop/python_intern/archive (1)/ims.np',\n",
    "    'mas_path': r'/home/hardik/Desktop/python_intern/archive (1)/mas.np',\n",
    "    'model_save_path': r'/home/hardik/Desktop/python_intern/unet_segmentation_model.pth',\n",
    "    'image_size': (256, 256),\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 4, # Adjust based on your system\n",
    "    'encoder': 'resnet34',\n",
    "    'encoder_weights': 'imagenet',\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7467f53",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing and Custom Dataset ðŸ’¾\n",
    "Defines the function to convert binary masks into a 3-class segmentation problem (Background: 0, Residential: 1, Commercial: 2) and the custom PyTorch `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiclass_masks(masks, building_counts):\n",
    "    \"\"\"\n",
    "    Convert binary masks to 3-class segmentation:\n",
    "    0 = background, 1 = residential, 2 = commercial (high density)\n",
    "    \"\"\"\n",
    "    # Determine the threshold for 'Commercial' density (e.g., top 10% density)\n",
    "    if len(building_counts) == 0: return np.zeros_like(masks, dtype=np.int64)\n",
    "    threshold = np.percentile(building_counts, 90)\n",
    "    multiclass_masks = np.zeros_like(masks, dtype=np.int64)\n",
    "    \n",
    "    for i in range(len(masks)):\n",
    "        mask = masks[i]\n",
    "        if building_counts[i] > threshold:\n",
    "            # Commercial (Class 2)\n",
    "            multiclass_masks[i] = np.where(mask > 0, 2, 0)\n",
    "        else:\n",
    "            # Residential (Class 1)\n",
    "            multiclass_masks[i] = np.where(mask > 0, 1, 0)\n",
    "    \n",
    "    return multiclass_masks\n",
    "\n",
    "\n",
    "# ==================== Custom Dataset ====================\n",
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].astype(np.float32)\n",
    "        mask = self.masks[idx].astype(np.int64)\n",
    "        \n",
    "        # Normalize image to [0, 1]\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "        \n",
    "        if self.transform:\n",
    "            # Albumentations expects HWC format, float32 image\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image'] # Already normalized and to Tensor (CHW)\n",
    "            mask = augmented['mask'] # Tensor (HW)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac9db9",
   "metadata": {},
   "source": [
    "## 2. Augmentation Pipelines ðŸ¤¸\n",
    "Defines the transformation pipelines for training (with augmentation) and validation (without augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation(image_size):\n",
    "    # Standard image normalization values for ImageNet pre-trained models\n",
    "    mean=(0.485, 0.456, 0.406)\n",
    "    std=(0.229, 0.224, 0.225)\n",
    "    \n",
    "    return A.Compose([\n",
    "        A.Resize(height=image_size[0], width=image_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5, border_mode=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "        A.Normalize(mean=mean, std=std), # Applies Z-score normalization\n",
    "        ToTensorV2(), # Converts to PyTorch Tensor and changes layout to CHW\n",
    "    ])\n",
    "\n",
    "def get_validation_augmentation(image_size):\n",
    "    mean=(0.485, 0.456, 0.406)\n",
    "    std=(0.229, 0.224, 0.225)\n",
    "    \n",
    "    return A.Compose([\n",
    "        A.Resize(height=image_size[0], width=image_size[1]),\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc28bc7",
   "metadata": {},
   "source": [
    "## 3. Loss Function and Metrics ðŸ“Š\n",
    "Implements a custom multiclass **Dice Loss** and combines it with **Cross-Entropy** for the final objective function. Also defines the **IoU** metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        # pred is logits (B, C, H, W)\n",
    "        # target is class indices (B, H, W)\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        \n",
    "        # Convert target to one-hot encoding (B, H, W, C) -> (B, C, H, W)\n",
    "        target_one_hot = torch.nn.functional.one_hot(target, num_classes=pred.shape[1])\n",
    "        target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Compute Dice for each class (Intersection and Union summed over H and W)\n",
    "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        # Dice formula: 2*I / (U + I)\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        # Return 1 - mean Dice score across all classes in the batch\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        # CrossEntropyLoss expects logits (pred) and class indices (target)\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        # Weighted sum of losses\n",
    "        return self.alpha * ce + (1 - self.alpha) * dice\n",
    "\n",
    "\n",
    "# ==================== Metrics ====================\n",
    "def calculate_iou(pred, target, num_classes=3):\n",
    "    \"\"\"Calculate Intersection over Union for each class\"\"\"\n",
    "    # Convert logits to class predictions\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    ious = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        # Intersection and Union\n",
    "        intersection = (pred_cls & target_cls).sum().float()\n",
    "        union = (pred_cls | target_cls).sum().float()\n",
    "        \n",
    "        # IoU formula: I / U\n",
    "        iou = (intersection + 1e-6) / (union + 1e-6) # Add epsilon for stability\n",
    "        ious.append(iou.item())\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce2af9",
   "metadata": {},
   "source": [
    "## 4. Training and Validation Loops âš™ï¸\n",
    "Defines the functions to execute one epoch of training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_iou = [0, 0, 0]\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        ious = calculate_iou(outputs, masks)\n",
    "        total_iou = [total_iou[i] + ious[i] for i in range(3)]\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'mean_iou': f'{np.mean(ious):.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_iou = [iou / len(dataloader) for iou in total_iou]\n",
    "    \n",
    "    return avg_loss, avg_iou\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_iou = [0, 0, 0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            ious = calculate_iou(outputs, masks)\n",
    "            total_iou = [total_iou[i] + ious[i] for i in range(3)]\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'mean_iou': f'{np.mean(ious):.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_iou = [iou / len(dataloader) for iou in total_iou]\n",
    "    \n",
    "    return avg_loss, avg_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f605b",
   "metadata": {},
   "source": [
    "## 5. Main Training Pipeline Execution ðŸš€\n",
    "Loads data, splits into train/val sets, initializes the model, runs the training loop, and visualizes results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        ims = jlb.load(CONFIG['ims_path'])\n",
    "        mas = jlb.load(CONFIG['mas_path'])\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Data files not found. Check 'ims_path' and 'mas_path' in CONFIG.\")\n",
    "        return\n",
    "    \n",
    "    ims = np.array(ims)\n",
    "    mas = np.array(mas)\n",
    "    \n",
    "    # Normalize masks shape (remove last channel if present)\n",
    "    if mas.ndim == 4 and mas.shape[-1] == 1:\n",
    "        mas = mas[..., 0]\n",
    "    \n",
    "    print(f\"Images shape: {ims.shape}\")\n",
    "    print(f\"Masks shape: {mas.shape}\")\n",
    "    \n",
    "    # Create multiclass masks\n",
    "    print(\"Creating multiclass masks...\")\n",
    "    # Sum of non-zero pixels (buildings) for each image\n",
    "    building_counts = np.sum(mas > 0, axis=(1, 2))\n",
    "    multiclass_masks = create_multiclass_masks(mas, building_counts)\n",
    "    \n",
    "    class_counts = [np.sum(multiclass_masks == i) for i in range(3)]\n",
    "    print(f\"Class distribution (Pixel Count) - Background: {class_counts[0]}, Residential (1): {class_counts[1]}, Commercial (2): {class_counts[2]}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        ims, multiclass_masks, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(X_train)}, Val samples: {len(X_val)}\")\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = SatelliteDataset(\n",
    "        X_train, y_train, \n",
    "        transform=get_training_augmentation(CONFIG['image_size'])\n",
    "    )\n",
    "    val_dataset = SatelliteDataset(\n",
    "        X_val, y_val, \n",
    "        transform=get_validation_augmentation(CONFIG['image_size'])\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        shuffle=True, \n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, \n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    print(\"Creating model...\")\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CONFIG['encoder'],\n",
    "        encoder_weights=CONFIG['encoder_weights'],\n",
    "        in_channels=3,\n",
    "        classes=3  # 0: background, 1: residential, 2: commercial\n",
    "    )\n",
    "    model = model.to(CONFIG['device'])\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = CombinedLoss(alpha=0.5)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    # Scheduler to dynamically adjust learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=5, factor=0.5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_iou': [], 'val_iou': []}\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        \n",
    "        train_loss, train_iou = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "        val_loss, val_iou = validate_epoch(model, val_loader, criterion, CONFIG['device'])\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_iou'].append(train_iou)\n",
    "        history['val_iou'].append(val_iou)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Train IoU - BG: {train_iou[0]:.4f}, Res: {train_iou[1]:.4f}, Com: {train_iou[2]:.4f}\")\n",
    "        print(f\"Val IoU - BG: {val_iou[0]:.4f}, Res: {val_iou[1]:.4f}, Com: {val_iou[2]:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'config': CONFIG\n",
    "            }, CONFIG['model_save_path'])\n",
    "            print(f\"âœ… Model saved with best val_loss: {val_loss:.4f}\")\n",
    "    \n",
    "    print(\"\\n\\n--- Training History Plots ---\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    train_iou_bg = [iou[0] for iou in history['train_iou']]\n",
    "    val_iou_bg = [iou[0] for iou in history['val_iou']]\n",
    "    plt.plot(train_iou_bg, label='Train IoU BG')\n",
    "    plt.plot(val_iou_bg, label='Val IoU BG')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.title('Background IoU')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    train_iou_res = [iou[1] for iou in history['train_iou']]\n",
    "    train_iou_com = [iou[2] for iou in history['train_iou']]\n",
    "    val_iou_res = [iou[1] for iou in history['val_iou']]\n",
    "    val_iou_com = [iou[2] for iou in history['val_iou']]\n",
    "    plt.plot(train_iou_res, label='Train Residential')\n",
    "    plt.plot(train_iou_com, label='Train Commercial')\n",
    "    plt.plot(val_iou_res, label='Val Residential')\n",
    "    plt.plot(val_iou_com, label='Val Commercial')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.title('Class-wise IoU')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/hardik/Desktop/python_intern/training_history.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n--- Prediction Visualization ---\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get one batch from the validation loader\n",
    "        sample_images, sample_masks = next(iter(val_loader))\n",
    "        sample_images = sample_images.to(CONFIG['device'])\n",
    "        predictions = model(sample_images)\n",
    "        predictions = torch.argmax(predictions, dim=1).cpu().numpy()\n",
    "    \n",
    "    # Denormalize images for visualization (reverse ImageNet normalization)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    n_samples = min(4, len(sample_images))\n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(12, 4*n_samples))\n",
    "    # Ensure axes is a 2D array even for n_samples=1\n",
    "    if n_samples == 1: axes = np.expand_dims(axes, 0)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        img = sample_images[i].cpu().numpy().transpose(1, 2, 0) # CHW -> HWC\n",
    "        # Denormalization\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1) # Clip to valid image range\n",
    "        \n",
    "        # Use a colormap suitable for discrete classes (0, 1, 2)\n",
    "        cmap = plt.cm.get_cmap('tab10', 3)\n",
    "        \n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('Input Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(sample_masks[i].cpu().numpy(), cmap=cmap, vmin=0, vmax=2)\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(predictions[i], cmap=cmap, vmin=0, vmax=2)\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "    # Add a custom legend for classes\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                          markerfacecolor=cmap(i), markersize=10) for i, label in enumerate(['Background', 'Residential', 'Commercial'])]\n",
    "    fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(1.15, 0.9))\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1.05, 1])\n",
    "    plt.savefig('/home/hardik/Desktop/python_intern/predictions.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ… Training complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
